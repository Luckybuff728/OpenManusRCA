# OpenManus - 微服务根因分析系统

欢迎来到 OpenManus，这是一个专为微服务架构设计的、由人工智能驱动的根因分析（RCA）系统。该系统利用大语言模型（LLM）自动化故障诊断流程，旨在缩短系统停机时间并降低运维成本。

## 系统概述

在复杂的微服务环境中，定位故障的根本原因是一项极具挑战性且耗时的工作。OpenManus 通过引入一个AI代理来解决这个问题，该代理能够系统性地分析遥测数据（包括日志、指标和追踪），从而精确定位导致故障的具体组件和原因。

系统的工作流程始于一个故障案例，该案例由一个时间范围和异常现象的描述定义。随后，系统采用一种由假设驱动的科学方法进行调查，逐步缩小可能性，直至找到最终结论。

## 核心功能

-   **AI驱动的智能分析**: 利用大语言模型（LLM）的推理能力来理解复杂的系统行为并诊断问题。
-   **假设驱动的调查方法**: 遵循结构化的科学调查方法，通过“提出假设->验证假设->得出结论”的循环来推进分析，确保整个过程逻辑严谨且透明。
-   **多源数据融合分析**: 能够关联来自多种数据源（日志、指标、追踪）的信息，构建出故障全景图，从而进行更全面的判断。
-   **自动化的工作流程**: 从数据收集、关联分析到最终诊断报告的生成，整个RCA流程完全自动化，无需人工干预。
-   **批量处理能力**: 支持一次性分析多个故障案例，提高了分析效率。
-   **标准化的分析报告**: 生成格式统一、内容清晰的JSON格式报告，详细说明故障的根本原因、相关组件以及分析过程的推理链条。
-   **灵活的配置**: 可以轻松配置以适应不同的LLM供应商和系统环境。

## 系统架构

OpenManus系统的核心是一个作为决策中心的人工智能代理（AI Agent）。该代理通过一套专用工具与各种数据源进行交互，执行其分析任务。

```
    A[用户输入] --> B{rca_main.py 入口};
    B --> C[RCA 代理];
    C --> D{思考-行动循环};
    D -- 思考 --> E[构建假设与行动计划];
    D -- 行动 --> F[执行工具调用];
    F --> G[AskDataExpert 数据专家工具];
    G --> H[数据加载器];
    H --> I[日志 (Parquet)];
    H --> J[指标 (Parquet)];
    H --> K[追踪 (Parquet)];
    I --> G;
    J --> G;
    K --> G;
    G -- 分析结果 --> D;
    D -- 最终结论 --> L[生成JSON报告];
    B --> L;
```

1.  **入口脚本 (`rca_main.py`)**: 用户通过命令行参数提供故障案例信息。这可以是一个单独的案例，也可以是一个包含多个案例的JSON文件。该脚本负责解析输入、初始化系统并启动分析流程。
2.  **RCA 代理 (`RCAAgent`)**: 这是系统的“大脑”。`rca_main.py`在接收到任务后，会创建一个`RCAAgent`实例。该代理负责管理整个分析的生命周期，包括维护对话历史、调用LLM以及执行工具。
3.  **思考-行动循环 (Think-Act Loop)**: 代理采用此循环模式来执行任务：
    *   **思考 (Think)**: 基于当前的故障信息、历史观察结果以及其内置的系统提示（其中定义了分析方法论），LLM会生成一段“思考”过程和一个具体的“行动计划”。
    *   **行动 (Act)**: 代理根据LLM生成的行动计划，调用最合适的工具来执行。
4.  **数据专家工具 (`AskDataExpert Tool`)**: 这是代理进行调查时使用的核心工具。它接收代理用自然语言描述的行动计划，然后将其转化为对具体数据源的查询和分析操作。
5.  **数据加载器 (`Data Loaders`)**: `AskDataExpert`工具内部使用一系列专门的数据加载器，负责从存储日志、指标和追踪的Parquet文件中高效地读取和筛选数据。
6.  **分析与结论**: 数据分析的结果会作为新的“观察”被反馈给代理，进入下一轮的“思考-行动”循环。这个过程会不断迭代，每一轮都会根据新的观察来修正或验证假设，直到代理有足够的信心确定根本原因。
7.  **JSON报告**: 分析完成后，代理会生成最终的JSON格式报告，其中包含故障组件、失败原因以及详细的推理路径。

## 快速入门

### 环境要求

-   Python 3.10 或更高版本
-   Pip 包管理器

### 安装步骤

1.  **克隆代码库:**
    ```bash
    git clone https://github.com/your-repo/OpenManus.git
    cd OpenManus
    ```

2.  **安装依赖:**
    ```bash
    pip install -r requirements.txt
    ```

### 系统配置

本应用的行为，特别是其连接的LLM，由 `config/config.toml` 文件控制。

1.  **复制示例配置文件:**
    ```bash
    cp config/config.example.toml config/config.toml
    ```

2.  **编辑 `config/config.toml`:**
    打开该文件，并在 `[llm]` 部分填入您选择的大语言模型提供商的详细信息（例如 OpenAI, Azure, Ollama 等）。

    ```toml
    [llm]
    # 模型名称, 例如 "gpt-4-turbo"
    model = "your-llm-model-name"
    # 您的LLM提供商的API基础URL
    base_url = "https://api.openai.com/v1"
    # 您的API密钥
    api_key = "sk-xxxxxxxxxxxxxxxxxxxxxxxx"
    # API类型, 例如 "openai", "azure"
    api_type = "openai"
    ```

## 使用方法

系统支持两种运行模式：分析单个案例或批量分析多个案例。

### 单案例分析

要分析单个故障，您需要提供一个UUID、一段描述性的查询，以及可选的开始和结束时间。

```bash
python rca_main.py \
  --uuid "unique-case-id-123" \
  --query "系统在 2025-06-05T16:10:00Z 到 2025-06-05T16:40:00Z 期间出现异常。前端服务错误率飙升。" \
  --start-time "2025-06-05T16:10:00Z" \
  --end-time "2025-06-05T16:40:00Z" \
  --output "results/unique-case-id-123.json"
```

如果省略 `--start-time` 和 `--end-time` 参数，脚本将尝试从 `--query` 字符串中自动提取时间范围。

### 批量分析

要分析多个案例，您可以提供一个输入JSON文件。项目在 `dataset/phaseone/input.json` 提供了一个示例文件。

```bash
python rca_main.py --input-json dataset/phaseone/input.json --output-dir results
```

该命令将处理 `input.json` 文件中定义的所有案例，并将每个案例的分析结果保存为独立的JSON文件到 `results/` 目录下。

您也可以使用 `--case-id` 标志来分析输入文件中的某一个特定案例：

```bash
python rca_main.py --input-json dataset/phaseone/input.json --case-id "345fbe93-80" --output-dir results
```

## 模块详解

```
.
├── app/                  # 核心应用逻辑
│   ├── agent/            # 包含RCA代理的核心逻辑 (rca.py)
│   ├── tool/             # 定义了代理可以使用的工具集
│   ├── prompt/           # 存放给予LLM的系统提示
│   ├── config.py         # 负责加载和管理应用配置
│   └── ...
├── config/               # 配置文件目录
│   ├── config.toml       # 主要配置文件 (LLM, 环境等)
│   └── ...
├── dataset/              # 存放用于分析的示例数据集
│   └── phaseone/
│       ├── input.json    # 批量分析的输入文件示例
│       └── ... (数据文件，格式为.parquet)
├── results/              # 分析报告的默认输出目录
├── rca_main.py           # 应用的主入口脚本
├── requirements.txt      # Python项目依赖列表
└── README.md             # 本文档
```

-   **`app/`**: 该目录包含了项目的所有核心业务逻辑。
    -   **`app/agent/`**: 定义了AI代理的行为。`rca.py` 是其中最重要的文件，它实现了 `RCAAgent` 类，包含了“思考-行动”循环的完整逻辑，并负责管理与LLM的交互和整个分析流程的状态。
    -   **`app/tool/`**: 这是代理的“工具箱”。每个工具都是一个独立的模块，代理可以通过调用它们来与外部世界（在这里是数据）进行交互。`ask_data_expert.py` 定义了核心的数据查询和分析工具。`loader.py` 则包含了用于从Parquet文件加载和处理数据的具体实现。
    -   **`app/prompt/`**: 这个目录存放着系统提示（System Prompt）。这些提示是指导LLM如何行动的关键。`rca.py` 中的提示文件定义了代理的角色、目标、必须遵循的分析方法论以及输出格式要求，从而确保了分析的质量和一致性。
    -   **`app/config.py`**: 该模块负责从 `config/config.toml` 文件中读取配置信息，并将其转化为应用程序可以方便使用的对象。

-   **`config/`**: 存放所有配置文件。`config.toml` 是主配置文件，你可以在这里设置LLM的凭据、模型名称等关键参数。

-   **`dataset/`**: 包含用于演示和测试的数据。`phaseone/input.json` 是一个批量任务的输入示例，它引用了同目录下的多个 `.parquet` 文件，这些文件是经过预处理的日志、指标和追踪数据。

-   **`results/`**: 当分析任务完成后，生成的JSON报告会默认保存在这个目录下。

-   **`rca_main.py`**: 这是整个应用程序的起点。它负责解析命令行参数，根据参数决定是执行单个任务还是批量任务，并最终初始化和运行 `RCAAgent`。

-   **`requirements.txt`**: 一个标准的Python文件，列出了项目运行所需的所有第三方库。
